<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on KurongBlog</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on KurongBlog</description>
    <image>
      <title>KurongBlog</title>
      <url>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.127.0</generator>
    <language>en</language>
    <lastBuildDate>Mon, 24 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AlexNet</title>
      <link>http://localhost:1313/posts/classicpapertranslation/alexnet/</link>
      <pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/classicpapertranslation/alexnet/</guid>
      <description>AlexNet Abstract 本文模型在2010的ImageNet LSVRC比赛数据集上取得了第一，top-1：37.5%，top-5：15.3%，远远超过第二名的top-5：26.2%。
AlexNet由5个卷积模块（包含了池化）、3个全连接、1个1000-way Softmax组成，使用非饱和神经元并在GPU上训练，同时为了减少过拟合，还采用了一种当时刚出现的正则化方法dropout。
1 Introduction 当时的目标识别为提高性能，常采用增大数据集、更好的model、更好的正则化技术阻止过拟合。
为了从ImageNet的数百万张高分辨的图像中学习到几千个对象，提出了CNNs（Convolutional nerual networks），其具有统计上的稳定性，并且对像素有局部性的依赖（卷积直接导致）。与相同层次的前馈相比，CNNs具有更少的连接和参数，更易于训练，但是理论最优性能稍差于前馈。
论文几个贡献：
在ILSVRC-2010和ILSVRC-2012[2]的ImageNet子集上训练了到目前为止最大的神经网络之一，并取得了迄今为止在这些数据集上报道过的最好结果； 编写了高度优化的2D卷积GPU实现以及训练卷积神经网络内部的所有其它操作； 使用了一些有效的技术来防止过拟合； CNNs的深度很重要，移除任何卷积层（每个卷积层包含的参数不超过模型参数的1%）都会导致更差的性能。 网络尺寸主要受限于目前GPU的内存容量和能忍受的训练时间。CNNs在两个GTX 580 3GB GPU上训练五六天。所有实验表明结果可以简单地通过等待更快的GPU和更大的可用数据集来提高。
2 The Dataset ImageNet数据集有超过1500万的标注高分辨率图像，这些图像属于大约22000个类别。这些图像是从网上收集的，使用了Amazon&amp;rsquo;s Mechanical Turk的众包工具通过人工标注的。从2010年起，作为Pascal视觉对象挑战赛的一部分，每年都会举办ImageNet大规模视觉识别挑战赛（ILSVRC）。ILSVRC使用ImageNet的一个子集，1000个类别每个类别大约1000张图像。总计，大约120万训练图像，50000张验证图像和15万测试图像。
ILSVRC-2010是ILSVRC竞赛中唯一可以获得测试集标签的版本，因此大多数实验都是在这个版本上运行的。由于模型参加了ILSVRC-2012竞赛，因此在之后包含模型在这个版本的数据集上的结果，这个版本的测试标签是不可获得的。在ImageNet上，按照惯例报告两个错误率：top-1和top-5，top-5错误率是指测试图像的正确标签不在模型认为的五个最可能的便签之中。
mageNet包含各种分辨率的图像，而CNNs要求输入固定维度。因此将图像进行下采样到固定的256×256分辨率。除了在训练集上对像素减去平均活跃度外，不对图像做任何其它的预处理。因此将在原始的RGB像素值上训练网络。
下采样步骤：给定一个矩形图像，首先缩放图像短边长度为256，然后从结果图像中裁剪中心的256×256大小的图像块。
3 The Architecture 下面内容是按照重要性排序的，3.1最重要。
3.1 ReLU Nonlinearity 下面的实验证明：使用饱和的激活函数（如Tanh）慢于非饱和的激活函数（如ReLU），且ReLU能较明显的加快训练速度。
右饱和： 当x趋向于正无穷时，函数的导数趋近于0，此时称为右饱和。
左饱和： 当x趋向于负无穷时，函数的导数趋近于0，此时称为左饱和。
饱和函数和非饱和函数： 当一个函数既满足右饱和，又满足左饱和，则称为饱和函数，否则称为非饱和函数。
常用的饱和激活函数和非饱和激活函数： 饱和激活函数有如Sigmoid和tanh，非饱和激活函数有ReLU；相较于饱和激活函数，非饱和激活函数可以解决“梯度消失”的问题，加快收敛。
采用ReLU的深度卷积神经网络训练时间比等价的Tanh单元要快几倍，对于一个特定的四层卷积网络，在CIFAR-10数据集上达到25%的训练误差所需要的迭代次数可以证实这一点。
使用ReLU的四层卷积神经网络在CIFAR-10数据集上达到25%的训练误差比使用tanh神经元的等价网络（虚线）快六倍。为了使训练尽可能快，每个网络的学习率是单独选择的，且没有采用任何类型的正则化。这里展示的效果的大小随网络结构的变化而变化，但使用ReLU的网络都比等价的饱和神经元快几倍。
3.2 Training on Multiple GPUs （该部分就是在说怎样用GPU训练的，略）
CNN架构图解，明确描述了两个GPU之间的责任。在图的顶部，一个GPU运行在部分层上，而在图的底部，另一个GPU运行在部分层上。GPU只在特定的层进行通信。网络的输入是150,528维，网络剩下层的神经元数目分别是253,440–186,624–64,896–64,896–43,264–4096–4096–1000（8层）。
3.3 Local Response Normalization 局部响应归一化有助于泛化。$a^i_{x,y}$表示激活的神经元，通过在$(x,y)$位置应用核$i$，然后应用ReLU计算。响应归一化激活$b^i_{x,y}$通过下式定义： $$ b^i_{x,y}=a^i_{x,y}/(k+α\sum_{j=max(0,i−n/2)}^{min(N−1,i+n/2)}(a^i_{x,y})^2)^β $$ 求和运算在$n$个“毗邻的”核映射的同一位置上执行，$N$是本层的卷积核数目。核映射的顺序当然是任意的，在训练开始前确定。响应归一化的顺序实现了一种侧抑制形式，灵感来自于真实神经元中发现的类型，为使用不同核进行神经元输出计算的较大活动创造了竞争。常量$k$，$n$，$α$，$β$是超参数，它们的值通过验证集确定。在本文中，设$k=2$，$n=5$，$α=0.0001$，$β=0.75$。在特定的层使用的ReLU非线性之后应用了这种归一化。
这个方案与Jarrett等人[11]的局部对比度归一化方案有一定的相似性，但更恰当的称其为“亮度归一化”，因此没有减去均值。响应归一化分别减少了top-1：1.4%，top-5：1.2%的错误率。之后在CIFAR-10数据集上验证了这个方案的有效性：一个四层CNN取得了13%的错误率，而使用归一化取得了11%的错误率。
Local Response Normalization(LRN)，局部响应归一化层。
首先要引入一个神经生物学的概念：侧抑制（lateral inhibitio），即指被激活的神经元抑制相邻的神经元。归一化（normaliazation）的目的就是“抑制”，LRN就是借鉴这种侧抑制来实现局部抑制，尤其是我们使用RELU的时候，这种“侧抑制”很有效 ，因而在alexnet里使用有较好的效果。</description>
    </item>
    <item>
      <title>记一次博客搭建</title>
      <link>http://localhost:1313/posts/daily-dev/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/daily-dev/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</guid>
      <description>My Blog Construction 前言 这是第二次用 Hugo 搭建静态博客了，之前的那个博客不论是主题、工作流、文件结构都很不合理，用起来效率低下。遂决定在研一之前重新搞一次。
完整过程 hugo 安装 在官方的 Releases · gohugoio/hugo (github.com) 下载对应版本即可，然后设置环境变量。
环境配置 网站选用 Github Pages 搭建，因为静态网站可以满足我的所有写作需求。域名就是仓库名705248010.github.io.
将仓库拉取到本地后就要开始配置了。先用
1 hugo new site &amp;lt;your site name&amp;gt; 生成一个对应文件夹，然后我将选择的主题 adityatelange/hugo-PaperMod: A fast, clean, responsive Hugo theme. (github.com) 放到 themes 文件夹内。
可以通过
1 hugo server 查看效果。
写Markdown 根据官方文档配置完成后就可以本地写文章了，用以下命令生成
1 hugo new --kind post ./xxxx/xxxx.md Github Actions（CI/CD）的使用 再之后就是编译生成静态文件并部署。Hugo的原生方式是在文件夹内使用 hugo 命令直接编译，然后把生成的 public 文件夹pull到仓库就部署完成。可是每次都这样就太麻烦了。
所以就要用到 Github Actions 自动部署了，我是从 Actions 中找的 Hugo 官方 yml 文件，一行未改就运行成功。在运行工作流之前记得把仓库设置中的 Actions 相关权限给了，还有把 Pages 中的 Deploy Source 设置为 Actions。</description>
    </item>
    <item>
      <title>记一次博客搭建</title>
      <link>http://localhost:1313/posts/test/test/</link>
      <pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/test/test/</guid>
      <description>$$a^*=x-b^*$$ $$ a^*=x-b^* $$ $$ a^*=x-b^* $$ $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$</description>
    </item>
  </channel>
</rss>
